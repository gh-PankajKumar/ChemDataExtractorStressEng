{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Properties: Example Code\n",
    "\n",
    "This notebook is a short tutorial on how the ChemDataExtractor code base can be used to extract records from an input article. Here, it will be assumed that the user has an article containing text based Yield Strength information which will be processed by ChemDataExtractor-StressEng.\n",
    "\n",
    "To source articles, please see the code contained in the \"Webscraping\" folder which can be used to download articles from Elsevier using their API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Relevant Modules\n",
    "\n",
    "The relevant ChemDataExtractor modules for extracting information are:\n",
    "\n",
    "- ```Document``` the input article will be converted into a Document object consisting of Paragraphs, Figures, Tables and other article elements which will be used for further processing.\n",
    "- ```ElsevierXmlReader``` as the input articles are from Elsevier, this reader will process the input article and handle the specific formatting tags in Elsevier XML files to convert into a ```Document``` object.\n",
    "- ```YieldStrength``` this is the property model that defines how to extract the information. See \"chemdataextractor/model/model.py\" for a full list of currently support property models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chemdataextractor import Document\n",
    "from chemdataextractor.reader.elsevier import ElsevierXmlReader\n",
    "from chemdataextractor.model.model import (\n",
    "    YieldStrength,\n",
    "    TableYieldStrength, \n",
    "    GrainSize, \n",
    "    TableGrainSize\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Processing an Input Article\n",
    "\n",
    "First, the article needs to be read and converted into a `Document` object for processing. This is done using the `Document.from_file` function which requires the path to the downloaded input article and optionally, which reader to use. Here, the `ElsevierXmlReader()` is used.\n",
    "\n",
    "Next, a property model is assigned to the `Document` object. Multiple property models can be assigned and these will all be used to extract the associated property from the document. In this case, only the `YieldStrength` property model is assigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Article\n",
    "downloaded_article_path = \"/PATH\"\n",
    "doc = Document.from_file(downloaded_article_path, readers=[ElsevierXmlReader()])\n",
    "\n",
    "extraction_model = YieldStrength\n",
    "doc.models = [extraction_model]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Metadata\n",
    "\n",
    "Having processed the input article into a `Document` object, the metadata of the article can be extracted. This will include information such as the article title, authors, doi and journal information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Metadata\n",
    "try:\n",
    "    metadata = doc.metadata.serialize()\n",
    "except:\n",
    "    metadata = \"Not Found\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing Article\n",
    "\n",
    "The parsers defined in the property models are then used to extract information from the `Document` resulting in a list of dictionaries of relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing article\n",
    "parsed_information = doc.records.serialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Complete Records\n",
    "\n",
    "From the parsed information, the records with an assigned compound name are extracted. Processing and article information are appended to the record and the result is a list of records containing dictionaries of material information. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Complete Records\n",
    "\n",
    "records = []\n",
    "\n",
    "for i in parsed_information:\n",
    "    if \"Compound\" in i:\n",
    "        continue\n",
    "    i[\"Article Metadata\"] = metadata\n",
    "    i[\"Extraction Model\"] = extraction_model\n",
    "    records.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Step\n",
    "\n",
    "Having extracted information from the article, the next step is to process the records through the Post Processing system which has been described in `PostProcessing.ipynb` in the Post_Processing code folder."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2417dda9ae24a3aad35855633c54e53628ebd1cd9ca3a57d978b30021ddff603"
  },
  "kernelspec": {
   "display_name": "Python 3.6.14 64-bit ('CDE': pyenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
